{
  "frames": [
    {
      "file": "frame_000.jpg",
      "time": 0.0,
      "log": "Capturing execution frames: simple.json"
    },
    {
      "file": "frame_001.jpg",
      "time": 0.21,
      "log": "Capturing execution frames: simple.json\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 4 nodes\n  [ComfyUI]   Node 2: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"bridge.jpg\"}\n  [ComfyUI]   Node 3: DownloadAndLoadDepthAnythingV3Model\n  [ComfyUI]     Inputs: {\"model\": \"da3_large.safetensors\", \"precision\": \"auto\"}\n  [ComfyUI]   Node 4: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"14\", 0]}\n  [ComfyUI]   Node 14: DepthAnything_V3\n  [ComfyUI]     Inputs: {\"normalization_mode\": \"V2-Style\", \"resize_method\": \"resize\", \"invert_depth\": true, \"keep_model_size\": false, \"da3_model\": [\"3\", 0], \"images\": [\"2\", 0]}\n  [ComfyUI] Generated prompt_id: 1f65778e-89f9-4e18-9948-48a911817fac\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  Queuing workflow for execution...\n  [ComfyUI] got prompt\n  [ComfyUI] [DepthAnythingV3] WARNING: WARNING: This model does not support sky segmentation. V2-Style normalization will work but without sky masking. Use Mono/Metric/Nested models for best V2-Style results.\n  [ComfyUI] [DepthAnythingV3] INFO: Input image size: 683x1024\n  [ComfyUI] [DepthAnythingV3] INFO: Model input size (after resize): 686x1022"
    },
    {
      "file": "frame_002.jpg",
      "time": 0.93,
      "log": "Capturing execution frames: simple.json\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 4 nodes\n  [ComfyUI]   Node 2: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"bridge.jpg\"}\n  [ComfyUI]   Node 3: DownloadAndLoadDepthAnythingV3Model\n  [ComfyUI]     Inputs: {\"model\": \"da3_large.safetensors\", \"precision\": \"auto\"}\n  [ComfyUI]   Node 4: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"14\", 0]}\n  [ComfyUI]   Node 14: DepthAnything_V3\n  [ComfyUI]     Inputs: {\"normalization_mode\": \"V2-Style\", \"resize_method\": \"resize\", \"invert_depth\": true, \"keep_model_size\": false, \"da3_model\": [\"3\", 0], \"images\": [\"2\", 0]}\n  [ComfyUI] Generated prompt_id: 1f65778e-89f9-4e18-9948-48a911817fac\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  Queuing workflow for execution...\n  [ComfyUI] got prompt\n  [ComfyUI] [DepthAnythingV3] WARNING: WARNING: This model does not support sky segmentation. V2-Style normalization will work but without sky masking. Use Mono/Metric/Nested models for best V2-Style results.\n  [ComfyUI] [DepthAnythingV3] INFO: Input image size: 683x1024\n  [ComfyUI] [DepthAnythingV3] INFO: Model input size (after resize): 686x1022\n  [ComfyUI] [DepthAnythingV3] INFO: Model output intrinsics (batch 0): shape=torch.Size([1, 1, 3, 3]), values="
    },
    {
      "file": "frame_003.jpg",
      "time": 1.09,
      "log": "Capturing execution frames: simple.json\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 4 nodes\n  [ComfyUI]   Node 2: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"bridge.jpg\"}\n  [ComfyUI]   Node 3: DownloadAndLoadDepthAnythingV3Model\n  [ComfyUI]     Inputs: {\"model\": \"da3_large.safetensors\", \"precision\": \"auto\"}\n  [ComfyUI]   Node 4: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"14\", 0]}\n  [ComfyUI]   Node 14: DepthAnything_V3\n  [ComfyUI]     Inputs: {\"normalization_mode\": \"V2-Style\", \"resize_method\": \"resize\", \"invert_depth\": true, \"keep_model_size\": false, \"da3_model\": [\"3\", 0], \"images\": [\"2\", 0]}\n  [ComfyUI] Generated prompt_id: 1f65778e-89f9-4e18-9948-48a911817fac\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  Queuing workflow for execution...\n  [ComfyUI] got prompt\n  [ComfyUI] [DepthAnythingV3] WARNING: WARNING: This model does not support sky segmentation. V2-Style normalization will work but without sky masking. Use Mono/Metric/Nested models for best V2-Style results.\n  [ComfyUI] [DepthAnythingV3] INFO: Input image size: 683x1024\n  [ComfyUI] [DepthAnythingV3] INFO: Model input size (after resize): 686x1022\n  [ComfyUI] [DepthAnythingV3] INFO: Model output intrinsics (batch 0): shape=torch.Size([1, 1, 3, 3]), values="
    },
    {
      "file": "frame_004.jpg",
      "time": 1.24,
      "log": "Capturing execution frames: simple.json\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 4 nodes\n  [ComfyUI]   Node 2: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"bridge.jpg\"}\n  [ComfyUI]   Node 3: DownloadAndLoadDepthAnythingV3Model\n  [ComfyUI]     Inputs: {\"model\": \"da3_large.safetensors\", \"precision\": \"auto\"}\n  [ComfyUI]   Node 4: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"14\", 0]}\n  [ComfyUI]   Node 14: DepthAnything_V3\n  [ComfyUI]     Inputs: {\"normalization_mode\": \"V2-Style\", \"resize_method\": \"resize\", \"invert_depth\": true, \"keep_model_size\": false, \"da3_model\": [\"3\", 0], \"images\": [\"2\", 0]}\n  [ComfyUI] Generated prompt_id: 1f65778e-89f9-4e18-9948-48a911817fac\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  Queuing workflow for execution...\n  [ComfyUI] got prompt\n  [ComfyUI] [DepthAnythingV3] WARNING: WARNING: This model does not support sky segmentation. V2-Style normalization will work but without sky masking. Use Mono/Metric/Nested models for best V2-Style results.\n  [ComfyUI] [DepthAnythingV3] INFO: Input image size: 683x1024\n  [ComfyUI] [DepthAnythingV3] INFO: Model input size (after resize): 686x1022\n  [ComfyUI] [DepthAnythingV3] INFO: Model output intrinsics (batch 0): shape=torch.Size([1, 1, 3, 3]), values=\n  [ComfyUI] tensor([[1.3413e+03, 0.0000e+00, 5.1100e+02],\n  [ComfyUI]         [0.0000e+00, 1.4490e+03, 3.4300e+02],\n  [ComfyUI]         [0.0000e+00, 0.0000e+00, 1.0000e+00]])\n  [ComfyUI] [DepthAnythingV3] INFO: Resizing from 686x1022 to 682x1024, scale: h=0.9942, w=1.0020\n  [ComfyUI] [DepthAnythingV3] INFO: Scaled intrinsics (batch 0):\n  [ComfyUI] tensor([[1.3440e+03, 0.0000e+00, 5.1200e+02],\n  [ComfyUI]         [0.0000e+00, 1.4405e+03, 3.4100e+02],\n  [ComfyUI]         [0.0000e+00, 0.0000e+00, 1.0000e+00]])\n  [ComfyUI] Prompt executed in 1.13 seconds"
    },
    {
      "file": "frame_005.jpg",
      "time": 1.46,
      "log": "Capturing execution frames: simple.json\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 4 nodes\n  [ComfyUI]   Node 2: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"bridge.jpg\"}\n  [ComfyUI]   Node 3: DownloadAndLoadDepthAnythingV3Model\n  [ComfyUI]     Inputs: {\"model\": \"da3_large.safetensors\", \"precision\": \"auto\"}\n  [ComfyUI]   Node 4: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"14\", 0]}\n  [ComfyUI]   Node 14: DepthAnything_V3\n  [ComfyUI]     Inputs: {\"normalization_mode\": \"V2-Style\", \"resize_method\": \"resize\", \"invert_depth\": true, \"keep_model_size\": false, \"da3_model\": [\"3\", 0], \"images\": [\"2\", 0]}\n  [ComfyUI] Generated prompt_id: 1f65778e-89f9-4e18-9948-48a911817fac\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  Queuing workflow for execution...\n  [ComfyUI] got prompt\n  [ComfyUI] [DepthAnythingV3] WARNING: WARNING: This model does not support sky segmentation. V2-Style normalization will work but without sky masking. Use Mono/Metric/Nested models for best V2-Style results.\n  [ComfyUI] [DepthAnythingV3] INFO: Input image size: 683x1024\n  [ComfyUI] [DepthAnythingV3] INFO: Model input size (after resize): 686x1022\n  [ComfyUI] [DepthAnythingV3] INFO: Model output intrinsics (batch 0): shape=torch.Size([1, 1, 3, 3]), values=\n  [ComfyUI] tensor([[1.3413e+03, 0.0000e+00, 5.1100e+02],\n  [ComfyUI]         [0.0000e+00, 1.4490e+03, 3.4300e+02],\n  [ComfyUI]         [0.0000e+00, 0.0000e+00, 1.0000e+00]])\n  [ComfyUI] [DepthAnythingV3] INFO: Resizing from 686x1022 to 682x1024, scale: h=0.9942, w=1.0020\n  [ComfyUI] [DepthAnythingV3] INFO: Scaled intrinsics (batch 0):\n  [ComfyUI] tensor([[1.3440e+03, 0.0000e+00, 5.1200e+02],\n  [ComfyUI]         [0.0000e+00, 1.4405e+03, 3.4100e+02],\n  [ComfyUI]         [0.0000e+00, 0.0000e+00, 1.0000e+00]])\n  [ComfyUI] Prompt executed in 1.13 seconds"
    },
    {
      "file": "frame_006.jpg",
      "time": 1.62,
      "log": "Capturing execution frames: simple.json\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 4 nodes\n  [ComfyUI]   Node 2: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"bridge.jpg\"}\n  [ComfyUI]   Node 3: DownloadAndLoadDepthAnythingV3Model\n  [ComfyUI]     Inputs: {\"model\": \"da3_large.safetensors\", \"precision\": \"auto\"}\n  [ComfyUI]   Node 4: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"14\", 0]}\n  [ComfyUI]   Node 14: DepthAnything_V3\n  [ComfyUI]     Inputs: {\"normalization_mode\": \"V2-Style\", \"resize_method\": \"resize\", \"invert_depth\": true, \"keep_model_size\": false, \"da3_model\": [\"3\", 0], \"images\": [\"2\", 0]}\n  [ComfyUI] Generated prompt_id: 1f65778e-89f9-4e18-9948-48a911817fac\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  Queuing workflow for execution...\n  [ComfyUI] got prompt\n  [ComfyUI] [DepthAnythingV3] WARNING: WARNING: This model does not support sky segmentation. V2-Style normalization will work but without sky masking. Use Mono/Metric/Nested models for best V2-Style results.\n  [ComfyUI] [DepthAnythingV3] INFO: Input image size: 683x1024\n  [ComfyUI] [DepthAnythingV3] INFO: Model input size (after resize): 686x1022\n  [ComfyUI] [DepthAnythingV3] INFO: Model output intrinsics (batch 0): shape=torch.Size([1, 1, 3, 3]), values=\n  [ComfyUI] tensor([[1.3413e+03, 0.0000e+00, 5.1100e+02],\n  [ComfyUI]         [0.0000e+00, 1.4490e+03, 3.4300e+02],\n  [ComfyUI]         [0.0000e+00, 0.0000e+00, 1.0000e+00]])\n  [ComfyUI] [DepthAnythingV3] INFO: Resizing from 686x1022 to 682x1024, scale: h=0.9942, w=1.0020\n  [ComfyUI] [DepthAnythingV3] INFO: Scaled intrinsics (batch 0):\n  [ComfyUI] tensor([[1.3440e+03, 0.0000e+00, 5.1200e+02],\n  [ComfyUI]         [0.0000e+00, 1.4405e+03, 3.4100e+02],\n  [ComfyUI]         [0.0000e+00, 0.0000e+00, 1.0000e+00]])\n  [ComfyUI] Prompt executed in 1.13 seconds"
    },
    {
      "file": "frame_007.jpg",
      "time": 2.82,
      "log": "Capturing execution frames: simple.json\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 4 nodes\n  [ComfyUI]   Node 2: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"bridge.jpg\"}\n  [ComfyUI]   Node 3: DownloadAndLoadDepthAnythingV3Model\n  [ComfyUI]     Inputs: {\"model\": \"da3_large.safetensors\", \"precision\": \"auto\"}\n  [ComfyUI]   Node 4: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"14\", 0]}\n  [ComfyUI]   Node 14: DepthAnything_V3\n  [ComfyUI]     Inputs: {\"normalization_mode\": \"V2-Style\", \"resize_method\": \"resize\", \"invert_depth\": true, \"keep_model_size\": false, \"da3_model\": [\"3\", 0], \"images\": [\"2\", 0]}\n  [ComfyUI] Generated prompt_id: 1f65778e-89f9-4e18-9948-48a911817fac\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  Queuing workflow for execution...\n  [ComfyUI] got prompt\n  [ComfyUI] [DepthAnythingV3] WARNING: WARNING: This model does not support sky segmentation. V2-Style normalization will work but without sky masking. Use Mono/Metric/Nested models for best V2-Style results.\n  [ComfyUI] [DepthAnythingV3] INFO: Input image size: 683x1024\n  [ComfyUI] [DepthAnythingV3] INFO: Model input size (after resize): 686x1022\n  [ComfyUI] [DepthAnythingV3] INFO: Model output intrinsics (batch 0): shape=torch.Size([1, 1, 3, 3]), values=\n  [ComfyUI] tensor([[1.3413e+03, 0.0000e+00, 5.1100e+02],\n  [ComfyUI]         [0.0000e+00, 1.4490e+03, 3.4300e+02],\n  [ComfyUI]         [0.0000e+00, 0.0000e+00, 1.0000e+00]])\n  [ComfyUI] [DepthAnythingV3] INFO: Resizing from 686x1022 to 682x1024, scale: h=0.9942, w=1.0020\n  [ComfyUI] [DepthAnythingV3] INFO: Scaled intrinsics (batch 0):\n  [ComfyUI] tensor([[1.3440e+03, 0.0000e+00, 5.1200e+02],\n  [ComfyUI]         [0.0000e+00, 1.4405e+03, 3.4100e+02],\n  [ComfyUI]         [0.0000e+00, 0.0000e+00, 1.0000e+00]])\n  [ComfyUI] Prompt executed in 1.13 seconds"
    },
    {
      "file": "frame_008.jpg",
      "time": 10.499622344970703,
      "log": "Final screenshot"
    }
  ],
  "total_time": 2.95
}